# LLM API å“åº”è½¬æ¢åˆ†æ

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ç»Ÿä¸€çš„LLM APIå“åº”è½¬æ¢ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§APIæ¶æ„ï¼ˆResponses APIå’ŒChat Completions APIï¼‰çš„ç»Ÿä¸€å¤„ç†ã€‚ç³»ç»Ÿé€šè¿‡é€‚é…å™¨æ¨¡å¼å°†ä¸åŒAPIçš„å“åº”è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„ç»Ÿä¸€æ ¼å¼ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

1. **ModelAdapterFactory** (<mcfile name="modelAdapterFactory.ts" path="src/services/modelAdapterFactory.ts"></mcfile>)
   - æ ¹æ®æ¨¡å‹èƒ½åŠ›é€‰æ‹©é€‚å½“çš„é€‚é…å™¨
   - æ”¯æŒAPIç±»å‹è‡ªåŠ¨æ£€æµ‹å’Œå›é€€æœºåˆ¶

2. **ResponsesAPIAdapter** (<mcfile name="responsesAPI.ts" path="src/services/adapters/responsesAPI.ts"></mcfile>)
   - å¤„ç†GPT-5 Responses APIæ ¼å¼
   - æ”¯æŒæ¨ç†æ‘˜è¦ã€å·¥å…·è°ƒç”¨ç­‰é«˜çº§åŠŸèƒ½

3. **ChatCompletionsAdapter** (<mcfile name="chatCompletions.ts" path="src/services/adapters/chatCompletions.ts"></mcfile>)
   - å¤„ç†ä¼ ç»ŸChat Completions APIæ ¼å¼
   - å‘åå…¼å®¹ç°æœ‰æ¨¡å‹

4. **ç»Ÿä¸€å“åº”æ ¼å¼** (<mcfile name="modelCapabilities.ts" path="src/types/modelCapabilities.ts"></mcfile>)
   - æ ‡å‡†åŒ–çš„å“åº”æ¥å£å®šä¹‰

## ğŸ”„ å“åº”è½¬æ¢æµç¨‹

### 1. APIè°ƒç”¨æµç¨‹

```
ç”¨æˆ·è¾“å…¥ â†’ query.ts â†’ claude.ts â†’ ModelAdapterFactory â†’ é€‚é…å™¨ â†’ APIè°ƒç”¨ â†’ å“åº”è§£æ â†’ ç»Ÿä¸€å“åº”æ ¼å¼
```

### 2. é€‚é…å™¨é€‰æ‹©é€»è¾‘

ModelAdapterFactoryæ ¹æ®ä»¥ä¸‹æ¡ä»¶é€‰æ‹©é€‚é…å™¨ï¼š

1. **æ¨¡å‹èƒ½åŠ›æ£€æµ‹**ï¼šæ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒResponses API
2. **ç«¯ç‚¹éªŒè¯**ï¼šéå®˜æ–¹OpenAIç«¯ç‚¹è‡ªåŠ¨ä½¿ç”¨Chat Completions
3. **å›é€€æœºåˆ¶**ï¼šæ”¯æŒä»Responses APIå›é€€åˆ°Chat Completions

### 3. Responses APIå“åº”è½¬æ¢

**è¾“å…¥æ ¼å¼** (Responses APIåŸç”Ÿå“åº”):
```typescript
{
  id: "resp_123",
  output_text: "å“åº”å†…å®¹",
  output: [
    { type: "reasoning", summary: [{ text: "æ¨ç†æ‘˜è¦" }] },
    { type: "message", content: [{ text: "æ¶ˆæ¯å†…å®¹" }] },
    { type: "tool_call", name: "tool_name", arguments: {} }
  ],
  usage: {
    input_tokens: 100,
    output_tokens: 50,
    output_tokens_details: { reasoning_tokens: 30 }
  }
}
```

**è½¬æ¢è¿‡ç¨‹** (<mcsymbol name="parseResponse" filename="responsesAPI.ts" path="src/services/adapters/responsesAPI.ts" startline="85" type="function"></mcsymbol>):
1. æå–åŸºç¡€æ–‡æœ¬å†…å®¹ (`output_text`)
2. å¤„ç†ç»“æ„åŒ–è¾“å‡º (`output`æ•°ç»„)
3. è§£æå·¥å…·è°ƒç”¨ (`tool_call`ç±»å‹)
4. è½¬æ¢ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯

**è¾“å‡ºæ ¼å¼** (ç»Ÿä¸€å“åº”):
```typescript
{
  id: "resp_123",
  content: "å“åº”å†…å®¹",
  toolCalls: [
    { id: "tool_123", type: "tool_call", name: "tool_name", arguments: {} }
  ],
  usage: {
    promptTokens: 100,
    completionTokens: 50,
    reasoningTokens: 30
  },
  responseId: "resp_123"
}
```

### 4. Chat Completions APIå“åº”è½¬æ¢

**è¾“å…¥æ ¼å¼** (Chat CompletionsåŸç”Ÿå“åº”):
```typescript
{
  id: "chatcmpl_123",
  choices: [{
    message: {
      content: "å“åº”å†…å®¹",
      tool_calls: [
        { id: "call_123", function: { name: "tool_name", arguments: "{}" } }
      ]
    }
  }],
  usage: {
    prompt_tokens: 100,
    completion_tokens: 50
  }
}
```

**è½¬æ¢è¿‡ç¨‹** (<mcsymbol name="parseResponse" filename="chatCompletions.ts" path="src/services/adapters/chatCompletions.ts" startline="67" type="function"></mcsymbol>):
1. æå–æ¶ˆæ¯å†…å®¹
2. è½¬æ¢å·¥å…·è°ƒç”¨æ ¼å¼
3. æ ‡å‡†åŒ–ä½¿ç”¨ç»Ÿè®¡å­—æ®µ

**è¾“å‡ºæ ¼å¼** (ç»Ÿä¸€å“åº”):
```typescript
{
  id: "chatcmpl_123",
  content: "å“åº”å†…å®¹",
  toolCalls: [
    { id: "call_123", type: "function", name: "tool_name", arguments: "{}" }
  ],
  usage: {
    promptTokens: 100,
    completionTokens: 50
  }
}
```

## ğŸ¯ ç»Ÿä¸€å“åº”æ ¼å¼

æ‰€æœ‰é€‚é…å™¨æœ€ç»ˆéƒ½è½¬æ¢ä¸ºç»Ÿä¸€çš„å“åº”æ ¼å¼ (<mcfile name="modelCapabilities.ts" path="src/types/modelCapabilities.ts"></mcfile>):

```typescript
interface UnifiedResponse {
  id: string                    // å“åº”ID
  content: string               // æ–‡æœ¬å†…å®¹
  toolCalls?: any[]            // å·¥å…·è°ƒç”¨æ•°ç»„
  usage: {                     // ä½¿ç”¨ç»Ÿè®¡
    promptTokens: number
    completionTokens: number
    reasoningTokens?: number   // GPT-5æ¨ç†ä»¤ç‰Œæ•°
  }
  responseId?: string          // Responses APIçŠ¶æ€ç®¡ç†ID
}
```

## ğŸ”§ ç‰¹æ®ŠåŠŸèƒ½å¤„ç†

### 1. è·¨æä¾›å•†å“åº”è½¬æ¢

é™¤äº†ç»Ÿä¸€çš„é€‚é…å™¨ç³»ç»Ÿï¼Œé¡¹ç›®è¿˜æ”¯æŒOpenAIåˆ°Anthropicæ ¼å¼çš„ç›´æ¥è½¬æ¢ (<mcsymbol name="convertOpenAIResponseToAnthropic" filename="claude.ts" path="src/services/claude.ts" startline="771" type="function"></mcsymbol>):

**è½¬æ¢è¿‡ç¨‹**:
```typescript
// OpenAIæ ¼å¼å“åº” â†’ Anthropicæ ¼å¼å“åº”
function convertOpenAIResponseToAnthropic(response: OpenAI.ChatCompletion) {
  // å¤„ç†æ¨ç†å†…å®¹ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
  if ((message as any).reasoning) {
    // å¤„ç†æ ‡å‡†æ¨ç†å†…å®¹
  }
  if ((message as any).reasoning_content) {
    // å¤„ç†DeepSeek APIçš„æ¨ç†å†…å®¹
  }
  
  // å¤„ç†å·¥å…·è°ƒç”¨
  if (message?.tool_calls) {
    // è½¬æ¢å·¥å…·è°ƒç”¨æ ¼å¼
  }
  
  // å¤„ç†æ–‡æœ¬å†…å®¹
  if (message.content) {
    // æ·»åŠ æ–‡æœ¬å—
  }
}
```

**é…ç½®é€‰é¡¹**:
- `thinkingOrder`: æ§åˆ¶æ¨ç†å†…å®¹å’Œå·¥å…·è°ƒç”¨çš„æ˜¾ç¤ºé¡ºåº
- `thinkingDisplay`: æ§åˆ¶æ¨ç†å†…å®¹çš„æ˜¾ç¤ºæ¨¡å¼ï¼ˆnone/full/head_tailï¼‰

### 2. æ¨ç†æ‘˜è¦å¤„ç†
GPT-5 Responses APIæä¾›æ¨ç†è¿‡ç¨‹æ‘˜è¦ï¼Œé€‚é…å™¨ä¼šå°†å…¶æ•´åˆåˆ°å“åº”å†…å®¹ä¸­ï¼š

```typescript
// åœ¨ResponsesAPIAdapter.parseResponseä¸­
if (response.output && Array.isArray(response.output)) {
  const reasoningItems = response.output.filter(item => item.type === 'reasoning')
  const messageItems = response.output.filter(item => item.type === 'message')
  
  if (reasoningItems.length > 0) {
    // å°†æ¨ç†æ‘˜è¦æ·»åŠ åˆ°å“åº”å†…å®¹å¼€å¤´
    const reasoningSummary = reasoningItems.map(item => /* æå–æ‘˜è¦ */).join('\n')
    content = `**æ¨ç†è¿‡ç¨‹:**\n${reasoningSummary}\n\n**å“åº”:**\n${content}`
  }
}
```

### 2. å·¥å…·è°ƒç”¨æ ¼å¼ç»Ÿä¸€åŒ–

ä¸åŒAPIçš„å·¥å…·è°ƒç”¨æ ¼å¼è¢«ç»Ÿä¸€ä¸ºï¼š
```typescript
// Responses APIæ ¼å¼
{ type: "tool_call", name: "tool_name", arguments: {} }

// Chat Completionsæ ¼å¼  
{ type: "function", name: "tool_name", arguments: "{}" }

// ç»Ÿä¸€æ ¼å¼
{ id: string, type: string, name: string, arguments: any }
```

### 3. æ¶ˆæ¯æ ¼å¼åŒå‘è½¬æ¢

é¡¹ç›®æ”¯æŒAnthropicå’ŒOpenAIæ¶ˆæ¯æ ¼å¼çš„åŒå‘è½¬æ¢ (<mcsymbol name="convertAnthropicMessagesToOpenAIMessages" filename="claude.ts" path="src/services/claude.ts" startline="520" type="function"></mcsymbol>):

**Anthropic â†’ OpenAI è½¬æ¢**:
```typescript
function convertAnthropicMessagesToOpenAIMessages(messages: AnthropicMessage[]) {
  // å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯å—
  for (const block of contentBlocks) {
    if (block.type === 'text') {
      // æ–‡æœ¬å— â†’ OpenAIæ–‡æœ¬æ¶ˆæ¯
      openaiMessages.push({
        role: message.message.role,
        content: block.text
      })
    } else if (block.type === 'tool_use') {
      // å·¥å…·ä½¿ç”¨å— â†’ OpenAIå·¥å…·è°ƒç”¨
      openaiMessages.push({
        role: 'assistant',
        content: undefined,
        tool_calls: [{
          type: 'function',
          function: {
            name: block.name,
            arguments: JSON.stringify(block.input)
          },
          id: block.id
        }]
      })
    } else if (block.type === 'tool_result') {
      // å·¥å…·ç»“æœå— â†’ OpenAIå·¥å…·ç»“æœæ¶ˆæ¯
      toolResults[block.tool_use_id] = {
        role: 'tool',
        content: typeof block.content !== 'string' 
          ? JSON.stringify(block.content) 
          : block.content,
        tool_call_id: block.tool_use_id
      }
    }
  }
  
  // ç¡®ä¿å·¥å…·è°ƒç”¨å’Œå·¥å…·ç»“æœçš„æ­£ç¡®é¡ºåº
  const finalMessages = []
  for (const message of openaiMessages) {
    finalMessages.push(message)
    if ('tool_calls' in message && message.tool_calls) {
      for (const toolCall of message.tool_calls) {
        if (toolResults[toolCall.id]) {
          finalMessages.push(toolResults[toolCall.id])
        }
      }
    }
  }
  
  return finalMessages
}
```

### 4. çŠ¶æ€ç®¡ç†
Responses APIæ”¯æŒå¯¹è¯é“¾å¼è°ƒç”¨ï¼Œé€šè¿‡`responseId`å’Œ`previousResponseId`å®ç°ï¼š

```typescript
// åœ¨åç»­è¯·æ±‚ä¸­ä¼ é€’å‰ä¸€ä¸ªå“åº”çš„ID
const nextResponse = await adapter.createRequest({
  // ...å…¶ä»–å‚æ•°
  previousResponseId: previousResponse.responseId
})
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

1. **èƒ½åŠ›ç¼“å­˜**ï¼šæ¨¡å‹èƒ½åŠ›ä¿¡æ¯åœ¨é¦–æ¬¡æŸ¥è¯¢åç¼“å­˜
2. **æ™ºèƒ½å›é€€**ï¼šéå®˜æ–¹ç«¯ç‚¹è‡ªåŠ¨ä½¿ç”¨Chat Completionsé¿å…å…¼å®¹æ€§é—®é¢˜
3. **é›¶å¼€é”€è®¾è®¡**ï¼šé€‚é…å™¨ç³»ç»Ÿåªåœ¨éœ€è¦æ—¶åˆ›å»ºï¼Œä¸å¢åŠ è¿è¡Œæ—¶å¼€é”€
4. **å“åº”ç¼“å­˜**ï¼šä½¿ç”¨LRUç¼“å­˜ç­–ç•¥ç¼“å­˜å¸¸è§æŸ¥è¯¢å“åº”ï¼ˆ5åˆ†é’ŸTTLï¼‰
5. **å¹¶è¡Œå¤„ç†**ï¼šæ”¯æŒæ‰¹é‡å·¥å…·æ‰§è¡Œï¼Œæé«˜å¤„ç†æ•ˆç‡

## ğŸ”„ æµå¼å“åº”å¤„ç†

### 1. æµå¼äº‹ä»¶ç±»å‹
ç³»ç»Ÿæ”¯æŒå¤šç§æµå¼äº‹ä»¶ç±»å‹ï¼Œç”¨äºå®æ—¶å¤„ç†LLMå“åº”ï¼š

```typescript
type QueryStreamEvent = 
  | { type: 'text_delta', text: string }          // æ–‡æœ¬å¢é‡
  | { type: 'tool_request', tool: ToolUse }      // å·¥å…·è¯·æ±‚
  | { type: 'tool_result', result: ToolResult }  // å·¥å…·ç»“æœ
  | { type: 'thinking', content: string }        // æ€è€ƒå†…å®¹
  | { type: 'error', error: Error }              // é”™è¯¯ä¿¡æ¯
  | { type: 'complete' }                         // å®Œæˆä¿¡å·
  | { type: 'usage', usage: TokenUsage }         // ä»¤ç‰Œä½¿ç”¨ç»Ÿè®¡
```

### 2. æµå¼å“åº”å¤„ç†å™¨
æµå¼å“åº”å¤„ç†å™¨è´Ÿè´£å°†åŸå§‹APIæµè½¬æ¢ä¸ºç»Ÿä¸€çš„äº‹ä»¶æµï¼š

```typescript
async function* handleStreamingResponse(
  stream: AsyncIterable<StreamEvent>
): AsyncGenerator<QueryStreamEvent> {
  for await (const event of stream) {
    switch (event.type) {
      case 'content_block_start':
        yield { type: 'text_delta', text: event.content }
        break
        
      case 'tool_use':
        yield { type: 'tool_request', tool: event.tool }
        break
        
      case 'message_stop':
        yield { type: 'complete' }
        break
    }
  }
}
```

### 3. æµç®¡ç†
æµç®¡ç†å™¨è´Ÿè´£ç¼“å†²å’Œå¤„ç†æµå¼æ•°æ®ï¼š

```typescript
class StreamManager {
  private buffer: string = ''
  private chunks: StreamEvent[] = []
  
  async *process(
    stream: ReadableStream
  ): AsyncGenerator<QueryStreamEvent> {
    const reader = stream.getReader()
    
    try {
      while (true) {
        const { done, value } = await reader.read()
        
        if (done) break
        
        // è§£æSSEäº‹ä»¶
        const events = parseSSE(value)
        
        for (const event of events) {
          yield* processEvent(event)
        }
      }
    } finally {
      reader.releaseLock()
    }
  }
}
```

## ğŸš¨ é”™è¯¯å¤„ç†æœºåˆ¶

### 1. é”™è¯¯æ¢å¤ç­–ç•¥
ç³»ç»Ÿå®ç°äº†æ™ºèƒ½çš„é”™è¯¯æ¢å¤æœºåˆ¶ï¼š

```typescript
async function* handleError(
  error: Error,
  context: QueryContext
): AsyncGenerator<QueryStreamEvent> {
  if (error.name === 'AbortError') {
    yield { type: 'cancelled' }
    return
  }
  
  if (error.name === 'RateLimitError') {
    // åˆ‡æ¢åˆ°å¤‡ä»½æ¨¡å‹
    const backupModel = getBackupModel()
    yield* retryWithModel(backupModel, context)
    return
  }
  
  if (error.name === 'ContextLengthError') {
    // å‹ç¼©å¹¶é‡è¯•
    const compacted = compactMessages(context.messages)
    yield* retryWithMessages(compacted, context)
    return
  }
  
  // ä¸å¯æ¢å¤çš„é”™è¯¯
  yield {
    type: 'error',
    error: formatError(error)
  }
}
```

### 2. ä¼˜é›…é™çº§
æ ¹æ®é”™è¯¯ç±»å‹é€‰æ‹©é€‚å½“çš„é™çº§ç­–ç•¥ï¼š

```typescript
function selectFallbackStrategy(error: Error): Strategy {
  switch (error.type) {
    case 'MODEL_UNAVAILABLE':
      return useAlternativeModel()
      
    case 'TOOL_FAILURE':
      return continueWithoutTool()
      
    case 'PERMISSION_DENIED':
      return requestAlternativeApproach()
      
    default:
      return reportErrorToUser()
  }
}
```

### 3. å·¥å…·æ‰§è¡Œç­–ç•¥
æ”¯æŒä¸²è¡Œå’Œå¹¶è¡Œå·¥å…·æ‰§è¡Œæ¨¡å¼ï¼š

```typescript
async function* executeTools(
  toolUses: ToolUse[],
  context: ToolContext
): AsyncGenerator<ToolExecutionEvent> {
  // ç¡®å®šæ‰§è¡Œç­–ç•¥
  const strategy = context.safeMode ? 'serial' : 'concurrent'
  
  if (strategy === 'concurrent') {
    // å¹¶è¡Œæ‰§è¡Œå·¥å…·
    yield* executeConcurrent(toolUses, context)
  } else {
    // ä¸ºå®‰å…¨ä¸²è¡Œæ‰§è¡Œå·¥å…·
    yield* executeSerial(toolUses, context)
  }
}
```

## ğŸ›¡ï¸ å…¼å®¹æ€§ä¿éšœ

1. **ç¯å¢ƒå˜é‡åˆ‡æ¢**ï¼šæ”¯æŒ`USE_NEW_ADAPTERS`å¼€å…³æ§åˆ¶æ–°è€ç³»ç»Ÿ
2. **100%å‘åå…¼å®¹**ï¼šè€ä»£ç ç»§ç»­ä½¿ç”¨åŸæœ‰çš„å“åº”å¤„ç†é€»è¾‘
3. **æ¸è¿›å¼è¿ç§»**ï¼šå¯ä»¥é€ä¸ªæ¨¡å‹è¿ç§»åˆ°æ–°ç³»ç»Ÿ

## ğŸš€ é«˜çº§åŠŸèƒ½

### 1. æ€è€ƒä»¤ç‰Œå¤„ç†
ç³»ç»Ÿæ”¯æŒå¤„ç†GPT-5çš„æ€è€ƒä»¤ç‰Œï¼Œæ ¹æ®é…ç½®å†³å®šæ˜¯å¦å‘ç”¨æˆ·æ˜¾ç¤ºï¼š

```typescript
function processThinkingTokens(
  response: APIResponse
): ProcessedResponse {
  const thinkingBlocks = extractThinkingBlocks(response)
  
  if (shouldShowThinking()) {
    return {
      ...response,
      thinking: thinkingBlocks
    }
  } else {
    // å‘ç”¨æˆ·éšè—æ€è€ƒå†…å®¹
    return {
      ...response,
      content: removeThinkingBlocks(response.content)
    }
  }
}
```

### 2. æ¨¡å‹åˆ‡æ¢
æ”¯æŒæ ¹æ®ä¸åŒçš„é”™è¯¯åŸå› æ™ºèƒ½åˆ‡æ¢æ¨¡å‹ï¼š

```typescript
class ModelSwitcher {
  async switchModel(
    reason: SwitchReason,
    currentModel: Model
  ): Promise<Model> {
    switch (reason) {
      case 'CONTEXT_TOO_LARGE':
        return this.getLargerContextModel()
        
      case 'RATE_LIMITED':
        return this.getBackupModel()
        
      case 'SPECIALIZED_TASK':
        return this.getSpecializedModel()
        
      default:
        return this.getDefaultModel()
    }
  }
}
```

### 3. é‡è¯•æœºåˆ¶
å®ç°æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥ï¼š

```typescript
async function* retryWithBackoff(
  operation: () => AsyncGenerator<QueryStreamEvent>,
  maxRetries: number = 3
): AsyncGenerator<QueryStreamEvent> {
  let retries = 0
  let delay = 1000
  
  while (retries < maxRetries) {
    try {
      yield* operation()
      return
    } catch (error) {
      if (!isRetryable(error)) throw error
      
      retries++
      yield {
        type: 'retry',
        attempt: retries,
        delay
      }
      
      await sleep(delay)
      delay *= 2 // æŒ‡æ•°é€€é¿
    }
  }
  
  throw new Error('Max retries exceeded')
}
```

## ğŸ“ˆ ç›‘æ§å’ŒæŒ‡æ ‡

### 1. æŸ¥è¯¢æŒ‡æ ‡è·Ÿè¸ª
ç³»ç»Ÿè·Ÿè¸ªè¯¦ç»†çš„æŸ¥è¯¢æ€§èƒ½æŒ‡æ ‡ï¼š

```typescript
interface QueryMetrics {
  startTime: number
  endTime: number
  tokensUsed: TokenUsage
  toolsExecuted: number
  errorsEncountered: number
  modelUsed: string
  cacheHit: boolean
}

function trackQuery(metrics: QueryMetrics): void {
  // è®°å½•åˆ°åˆ†æç³»ç»Ÿ
  analytics.track('query_completed', metrics)
  
  // æ›´æ–°æˆæœ¬è·Ÿè¸ª
  updateCostTracking(metrics.tokensUsed, metrics.modelUsed)
  
  // æ€§èƒ½ç›‘æ§
  if (metrics.endTime - metrics.startTime > 30000) {
    logSlowQuery(metrics)
  }
}
```

### 2. æ€§èƒ½ç›‘æ§
- **æ…¢æŸ¥è¯¢æ—¥å¿—**ï¼šè¶…è¿‡30ç§’çš„æŸ¥è¯¢ä¼šè¢«è®°å½•
- **æˆæœ¬è·Ÿè¸ª**ï¼šå®æ—¶è·Ÿè¸ªä»¤ç‰Œä½¿ç”¨æˆæœ¬
- **ç¼“å­˜å‘½ä¸­ç‡**ï¼šç›‘æ§ç¼“å­˜æ•ˆæœ
- **é”™è¯¯ç‡ç»Ÿè®¡**ï¼šè·Ÿè¸ªç³»ç»Ÿç¨³å®šæ€§

## ğŸ” è°ƒè¯•ä¿¡æ¯

ç³»ç»Ÿè®°å½•è¯¦ç»†çš„LLMäº¤äº’ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
- ä½¿ç”¨çš„APIç±»å‹ï¼ˆResponses/Chat Completionsï¼‰
- å®é™…è°ƒç”¨çš„ç«¯ç‚¹
- å“åº”è½¬æ¢è¿‡ç¨‹ä¸­çš„ä»»ä½•è°ƒæ•´
- ä»¤ç‰Œä½¿ç”¨ç»Ÿè®¡

## ğŸ“ æ€»ç»“

æœ¬é¡¹ç›®é€šè¿‡ç»Ÿä¸€çš„é€‚é…å™¨ç³»ç»ŸæˆåŠŸè§£å†³äº†ä¸åŒLLM APIå“åº”æ ¼å¼çš„å…¼å®¹æ€§é—®é¢˜ï¼Œæä¾›äº†ï¼š

1. **æ ‡å‡†åŒ–æ¥å£**ï¼šæ‰€æœ‰æ¨¡å‹è¿”å›ç»Ÿä¸€çš„å“åº”æ ¼å¼
2. **æ™ºèƒ½é€‚é…**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„APIç±»å‹
3. **é«˜çº§åŠŸèƒ½æ”¯æŒ**ï¼šå®Œæ•´æ”¯æŒGPT-5çš„é«˜çº§ç‰¹æ€§
4. **æ— ç¼è¿ç§»**ï¼šæ”¯æŒæ¸è¿›å¼ä»è€ç³»ç»Ÿè¿ç§»
5. **å®Œå–„ç›‘æ§**ï¼šè¯¦ç»†çš„è°ƒè¯•å’Œæ€§èƒ½ç»Ÿè®¡ä¿¡æ¯

è¿™å¥—ç³»ç»Ÿä¸ºåç»­æ”¯æŒæ›´å¤šLLMæä¾›å•†å’ŒAPIæ¶æ„å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚